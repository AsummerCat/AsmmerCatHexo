---
title: 面试相关-多线程
date: 2020-02-03 23:28:29
tags: [面试相关,多线程]
---

# 多线程

### 创建线程方式

```
1.继承 Thread 类 
2.实现runnable类

3.实现Callable类   传入RunableFutuer<V>
 FutureTask<Integer> a= new FutureTask(Callable<V>)
 new Thread(a);
 返回值:a.get();   ->如果未获取到结果会阻塞 可放入主线程最后
 判断是否计算结束: a.idDone()
 
```

### 线程状态转换

<!--more-->

```
新建线程
就绪
阻塞
等待
等待超时
结束线程
```

### 线程锁相关

```
同步代码块
locks锁
信号量   semaphone
回环栅栏  cyclicBarrier
JUC工具类
CAS 
使用原子类 AtomicInt AtomicLong
```

![](/img/2020-02-03/10.png)

###  Atomic 原子类

```
并发包 java.util.concurrent 的原子类都存放在java.util.concurrent.atomic下,
```

### AQS 组件总结

```
思想是: 有共享资源限制 当前线程为有效线程则锁定该资源 如果共享资源被占用 则有一套线程机制去阻塞唤醒
```

#### 概念

```
一个队列 去做加锁的操作
AQS  内部: state:加锁状态  ,当前加锁线程 , 队列 

:比如 A线程 加锁 AQS-> 会有一个state标记是否加锁 和当前加锁进程 ,还有一个队列(锁排队)
(公平锁)B线程 拿不到锁加入队列等待 A锁释放 从队列头部获取线程
(非公平锁)B线程 拿不到锁 等待 A释放 C线程先执行CAS操作到当前锁

```

![](/img/2020-02-03/11.png)

####  基于AQS实现的

```
Semaphore(信号量)
CountDownLatch （倒计时器)
CyclicBarrier(循环栅栏)
```

### signal()和await()的使用

```
1.await()：导致当前线程等待，直到其他线程调用该Condition的signal()或signalAll()方法唤醒该线程。

2、signal()：唤醒在此Lock对象上等待的单个线程。

3、signalAll()：唤醒在此Lock对象上等待的所有线程。
```

# 锁相关 JUC包下

### 公平锁&非公平锁

```
公平锁: 按照申请锁的顺序 

非公平锁: 不按照申请锁的顺序, 高并发情况下 可能造成优先级反转or饥饿现象(某个线程重复被插队) 优点:吞吐量比公平锁大


实现:
1.ReentrantLock 可重入锁 默认非公平锁 添加参数 可修改为公平锁
new ReentrantLock()   true 为公平锁
底层:默认 new NofairSync()

2. Synchronized 同步块 也是非公平锁

```

### 可重入锁(又名递归锁)

```
可以重复加锁 加两把锁等~
 统一线程 外部获取锁之后 内部函数仍然可以获取该锁代码
外部获取锁之后,在进入内部方法会自动获取锁

意思是: 也就是 加锁的A函数调用加锁的B函数  获取的是同一把锁
最大作用:  避免死锁

实现:
1.ReentrantLock
2.Synchronized
```

### 自旋锁

```
意思是: 尝试使用循环的方式获取锁  
好处: 减少线程上下文切换 
坏处: 循环会消耗CPU

例如CAS 和原子类
```

### 读写锁(独占写,共享读)&互斥锁

```
独占锁: 只能一个线程获取锁

共享锁: 该锁被多个线程持有

ReentrantReadWriteLock 其读锁是共享锁, 写锁是独享锁

读写,写读,和写写的过程是独享的,  读读是共享的 
```



### CountDownLatch 倒计数

```
countdown() 减计数
await()  等待计数结束

```

### CyclicBarrier 栅栏

```
可循环的栅栏 例如开会 人满开会 下一次人满 接着开会

构造: CyclicBarrier(int parties,Runable barrierAction)
人满 执行线程

方法:
await() 等待人满

```

### Semaphore 信号量

```
并发线程控制

Semaphore(int permits,boolean fair) 默认非公平

方法:
semaphore.acquire() 获取资源
semaphore.release() 释放资源

```

### 阻塞队列7种

```
ArrayBlockingQueue    ->基于数组结构的有界阻塞队列 先进先出 FIFO

LinkedBlockingQueue   ->基于链表结构的有界(int最大值)队列 先进先出 FIFO 吞吐量大于ArrayBlockingQueue

SynchronousQueue      ->一个不存储元素的堵塞队列 必须执行移除操作后才能放入一个元素 吞吐量要高

PriorityBlockingQueue ->一个优先级排序的无界队列

DelayQueue            ->使用优先级队列实现的延迟无界阻塞队列

LinkedTransferQueue   ->一个链表结构 无序的无界阻塞队列

LinkedBlockingDeque   ->一个链表组成的双向阻塞队列

队列为空 获取阻塞
队列为满 插入阻塞
有界队列 不会自动扩容

多线程情况下不用考虑多线程的安全问题 .

核心方法:
add() remove() element() 失败抛出异常
offer() poll() peek() 失败返回false 空为null 成功true
put() take() 阻塞
offer(时间) poll(时间) 超时

```

# 线程池使用

### 线程池有5种

```
FixedThreadPool ：该方法返回一个固定线程数量的线程池。

SingleThreadExecutor： 方法返回一个只有一个线程的线程池。

CachedThreadPool： 该方法返回一个可根据实际情况调整线程数量的线程池。

newScheduledThreadPool: 根据时间调度的线程池

java8新出:
newWorkStealingPool(int)  并行线程池
```

### 创建方式

```
 ExecutorService threadPool=Executors.FixedThreadPool()
 使用方式:
 1.无返回值  theadPool.execute()
 2.有返回值  theadPool.submit()
```

### 底层

```
都是使用阻塞队列
return 使用的都是 ThreadPoolExecutor

工作流程:
1.提交任务
2.判断核心线程是否已满       不满->创建线程执行任务  满-> 添加队列
3.判断队列                 不满 ->任务添加进入队列,判断是否达到最大线程   
                            满->拒绝策略

```

### 底层构造参数5个, 重载7个

```
corePoolSize           线程池中常驻核心线程数
maxImumPoolSize        线程池中最大的线程数
keepAliveTime          多余的空闲线程的存活时间
unit                   keepAliveTime的单位
workQueue              任务队列,被提交但尚未被执行的任务
threadFactory          代表生成线程池中工作线程的线程工厂,用于创建线程
handler                拒绝策略 ,线程满的时候执行
```

### 拒绝策略4种

```
AbortPolicy(默认) : 直接抛出RejectedExecutionException异常

CallerRunsPolicy: 一种调节机制 不抛弃任务,也不抛出异常 回退到调用者 降低流量

DiscardOldestPolicy: 抛弃队列中等待最久的任务 然后把当前任务加入队列

DiscardPolicy: 直接抛弃任务 (最好)

均实现RejectedExecutionHandler接口
```



# 真题

### synchronized 锁的升级是什么?

```
锁存在四种状态 分别是：无锁、偏向锁、轻量级锁、重量级锁； 锁的状态 根据竞争激烈的程度从低到高不断升级。
```

### ThreadLocal的作用?

```
将内存中的数据复制多份 每个线程都只能操作当前自己的那一份数据
```

### AQS 是什么

```
有共享资源限制 当前线程为有效线程则锁定该资源 如果共享资源被占用 则有一套线程机制去阻塞唤醒
locks包下的
```

### await()和sleep()的区别?

```
wait()一般用于Synchronized中，而await()只能用于ReentrantLock锁中

对锁的持有不同，wait()会释放锁，而sleep()并不释放锁

wait是Object方法,sleep是Thread方法
 wait要在同步块中使用,sleep在任何地方使用
 wait不需要捕获异常,sleep需要
```

### 简单介绍一下进程的切换过程

```
线程上下文的切换代价,要回答,切换会保存寄存器,栈等线程相关的现场,需要由用户态切换到内核态,可以用vmstat命令查看线程上下文的切换状况
```

### 保证线程安全的方法有哪些?

```
CAS,synchronized,lock,ThreadLocal
```

### 如何尽可能提高多线程并发性能?

```
 减少临界区范围
 使用ThreadLocal
 减少线程切换
 使用读写锁或CopyOnWrite
```

### 如何造成死锁?

```
1.资源分配不当
2.互相争抢资源 比如 A线程获取持有B锁 再获取A锁  
 B线程获取持有A锁 再获取B锁
 这样就造成死锁了
```

### 如何检测死锁?

```
java /bin下的
1. jps定位java线程             根据 jps -l 获取线程 
2. jstack找到死锁              jstack 线程号 获取线程信息


内存溢出可用jmap
```

### 分布式锁的选择

```
redis:  redisson
zk:     curator 
```

### JMM是什么?

```
JVM内存模型 (约定俗成)
在多线程中保证
  1.可见性
  2.有序性
  3.原子性
```

### 如何保证volatile的原子性?

```
使用原子类
volatile只保证了可见性 和 有序性 (禁止指令重排) 不保证原子性
```

### 内存屏障是什么?

```
通过插入内存屏障禁止在内存屏障的前后执行指令重排

内存屏障的另外一个作用:强制刷出各种CPU缓存数据 使其读取到都是最新数据
```

### CAS的ABA问题?

```
A线程修改 为A B线程修改A为B 而后修改为A	 对于A线程来说 原值不变可进行CAS操作
但是 中间A的值被操作修改过
避免这个问题 
1.可用原子引用地址 atomicReference<V>
2.原子引用地址+修改版本号(类似时间戳)  带时间戳的原子引用 atomicStampedReference
```

### synchronized和lock的区别?

```
          synchronized                       lock
构成:        JVM层面,关键字                    应用层,是api
底层:    monitorenter和monitorexit指令
使用:       不需要手动释放                      需要手动释放 unlock()
是否可中断:    不可中断                         可中断
加锁是否公平:   非公平                       默认非公平 可设置公平锁
绑定多个Condition: 没有                        可以加入多个进行分组 精确唤醒
```

### 为什么要不直接使用线程池而要自定义?

```
1.直接使用Thread创建 造成资源消耗

2.直接使用线程池
    定长线程池: linkedBlockingQueue 没有限制大小 造成请求堆积 OOM
    同步线程池: 跟上同理
    缓存线程池: 没有限制大小 造成创建线程堆积 OOM
    定时线程池 :跟上同理

```

### 如何合理配置线程池?

```
1.IO密集型(多线程查询数据库):  1.1最大线程数 CPU*2
                            1.2 CPU核数/1-阻塞系数(0.8~0.9)  例如8核CPU:8/1-0.9=80个线程数

2.CPU密集型(多线程进行循环操作):  最大线程数 CPU+1
```

### 分布式锁 redis和zk的选择?

```
zk优与redis

redis 分布式锁 需要不断去参数获取锁,比较消耗性能

zk 分布式锁 获取不到锁只要注册监听器就可以了

zk分布式锁 语义清晰 客户端挂了节点也就消失了 
redis还需要考虑其他因素,遍历上锁超时时间等

```

